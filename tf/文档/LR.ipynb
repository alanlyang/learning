{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599710142228",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的包\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import data as tfdata\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import losses\n",
    "from tensorflow.keras import initializers as init\n",
    "\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成随机数据\n",
    "def getData(num_samples, num_dim, w_real, b_real):\n",
    "    # 满足正太分布的随机数据\n",
    "    features = tf.random.normal((num_samples, num_dim), stddev=1)\n",
    "    # 真实数据\n",
    "    lables = features[:,0]*w_real[0] + features[:,1]*w_real[1] + b_real\n",
    "    # 给lables加上噪声\n",
    "    lables += tf.random.normal(lables.shape, stddev=0.01)\n",
    "\n",
    "    return features, lables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "num_dim = 2\n",
    "w_real = [2, -3.4]\n",
    "b_real = 4.14\n",
    "\n",
    "features, lables = getData(num_samples, num_dim, w_real, b_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(features[:, 1][0])\n",
    "print(lables.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(features[:, 1], 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置网络结构\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 一层全链接层,初始化参数满足正态分布\n",
    "model.add(layers.Dense(1, kernel_initializer=init.RandomNormal(stddev=0.01)))\n",
    "# loss函数： MSE\n",
    "loss = losses.MeanSquaredError()\n",
    "# 优化器： 随机梯度下降\n",
    "trainer = optimizers.SGD(learning_rate=0.03)\n",
    "\n",
    "plot_model(model)\n",
    "# 设置数据集和小批量的样本数\n",
    "batch_size = 10\n",
    "dataset = tfdata.Dataset.from_tensor_slices((features, lables))\n",
    "dataset = dataset.shuffle(len(features)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # 按batch进行计算\n",
    "    for (batch, (X, y)) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            l = loss(model(X, training=True), y)\n",
    "        # 计算梯度并更新参数\n",
    "        grads = tape.gradient(l, model.trainable_variables)\n",
    "        trainer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    # 迭代后的总loss\n",
    "    l = loss(model(features), lables)\n",
    "    print('epoch:%d \\t loss:%f'%(epoch, l.numpy().mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}