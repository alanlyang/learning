## keras Sequential/ Functional API 模式建立模型

    - Sequential
        当需要建立一个结构相对简单和典型的神经网络，如（MLP,CNN）等时，可以使用keras提供的api来进行模型的构建。
        最常用的神经网络结构时将一堆层按特定顺序堆叠起来，keras提供了
            tf.kears.Sequential() 来提供一个层的列表，来快速的建立一个tf.keras,Model模型并返回
        例如：
        model = tf.kears.Sequential(
            [
                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(100, activation=tf.nn.relu)
            ]
        )
        这种方式不能表示任意的神经网络结构（只能从上往下顺序堆叠）。

    - Functional API（）
        - 为了解决Sequential不能建立复杂模型的问题
        - 例如： 多输入/输出模型、 存在参数共享的模型
        - 使用方法
          - 将层作为可调用对象
          - 返回tensor
          - 将输入tensor和输出tensor提供给 tf.keras.Model的inputs 和 outputs
        - 模型建立完成后，通过tf.keras.Model和compile方法进行训练配置
          - compile接受三个参数
            - optimizer 优化器
            - loss 损失函数
            - metrics 评估指标
        - 最后使用tf.keras.Model的fit方法进行训练
          - fit 接受5个参数
            - x 训练数据
            - y lable
            - epochs 迭代次数
            - batch_size 批次的大小
            - validation_data 验证数据
        - 最后使用evaluate评估训练效果
          - evaluate接受两个参数
            - 测试数据
            - 测试label
    

## Flatten层
    用来将多维的数据一维化，将数据'压平'， 常用在"卷积层到全链接层的过度"
    Flatten不影响batch的大小

## Initializers
    初始化器用来设置keras隔层权重随机初始值的方法
    用来将初始化器传入keras层的参数名具体取决于具体的层。通常关键字为kernel_initializer和bias_initializer

    例如:
        model.add(Dense(64, kernel_initialize=tf.keras.initializer.RandomNormal))
    
    常用initializer
        - 1、Zeros() 将张量初始值设置为0的初始化器
        - 2、Ones()  将张亮初始值设置为1的初始化器
        - 3、Constant() 将tensor设置为一个常数
        - 4、RandomNormal()按照正态分布生成随机张亮的初始化器
            - mean: 随机值的平均数
            - stddev: 平均数的标准差
            - seed：随机数的种子
        - 5、RandomUniform() 按照均匀分布生成随机量的初始化器
        - 6、TruncatedNormal() 按照截尾正太分布生成随机tensor, 通常用来生成神经网络权重和滤波器的推荐初始化器
        - 7、Identity: 生成单位矩阵的初始化器，仅用于2D方阵
  
## from_tensor_slice
    - 在tf.data.Dataset中, Dataset API主要用于数据读取，构建输入数据的Pipline
    - 返回一个Dataset对象
    - 参数为tensors
      - 每一个都在第0维具有相同的大小
      - 是tensor的嵌套结构
    - 返回除下第一维的其他数据

## tf.GradientTape
    

