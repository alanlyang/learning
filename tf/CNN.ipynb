{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599876976580",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用keras实现卷积神经网络\n",
    "这里仍然使用mnist数据   \n",
    "通过tf.keras.Model来自定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import data as tfdata\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import losses\n",
    "from tensorflow.keras import initializers as init\n",
    "\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNistLoader():\n",
    "    def __init__(self):\n",
    "        # 定义mnist对象\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        # 读取mnist数据\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # mnist的数据为 28*28的0~255的值, 需要将图像转化为[张数， 宽度， 高度， 通道]， 并归一化\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32)/255.0, axis=-1)\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32)/255.0, axis=-1)\n",
    "\n",
    "        self.train_label = self.train_label.astype(np.float32)\n",
    "        self.test_label = self.test_label.astype(np.float32)\n",
    "\n",
    "        # 统计相关信息\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        # 从train_data中随机抽出batch_size个数据\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        # np数组可以接受list索引，返回list索引对应的值, 原生数据不支持\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义CNN模型\n",
    "和MLP相比，只是新加入了卷积层和池化层，这里的网络结构并不唯一，可以增加、删除、调整CNN的网络结构和参数，以达到更好的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        # 继承父类的属性和方法\n",
    "        super().__init__()\n",
    "        # 定义网络层\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            # 卷积层神经元（卷积核）数目, 默认使用kernel_initializer默认使用glorot_uniform进行初始化，简单来讲就是有32个不一样的卷积核，可以指定kernel_initializer\n",
    "            filters=32,\n",
    "            # 感受野大小\n",
    "            kernel_size=[5, 5],\n",
    "            # padding策略, same/vaild, same表示图片卷积后大小不变，valid表示卷积后图像减小（不对标远进行填充）\n",
    "            padding='same',\n",
    "            # 激活函数\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "\n",
    "        self.pool1 = layers.MaxPool2D(\n",
    "            pool_size=[2,2],\n",
    "            strides=2\n",
    "        )\n",
    "\n",
    "        self.conv2 = layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5,5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "\n",
    "        self.pool2 = layers.MaxPool2D(pool_size=[2,2], strides=2)\n",
    "        # TODO, 和Flatten的区别是什么\n",
    "        self.flatten = layers.Reshape(target_shape=(7*7*64, ))\n",
    "        self.dense1 = layers.Dense(units=1024, activation=tf.nn.relu)\n",
    "        self.dense2 = layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参和实例化对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参\n",
    "batch_size = 50\n",
    "epoch = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化数据和模型对象\n",
    "mnist = MNistLoader()\n",
    "cnn = CNN()\n",
    "\n",
    "# \n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_batches \n",
    "num_batches = int(mnist.num_train_data*epoch//batch_size)\n"
   ]
  }
 ]
}