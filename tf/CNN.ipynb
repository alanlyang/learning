{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599876976580",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用keras实现卷积神经网络\n",
    "这里仍然使用mnist数据   \n",
    "通过tf.keras.Model来自定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import data as tfdata\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import losses\n",
    "from tensorflow.keras import initializers as init\n",
    "\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNistLoader():\n",
    "    def __init__(self):\n",
    "        # 定义mnist对象\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        # 读取mnist数据\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # mnist的数据为 28*28的0~255的值, 需要将图像转化为[张数， 宽度， 高度， 通道]， 并归一化\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32)/255.0, axis=-1)\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32)/255.0, axis=-1)\n",
    "\n",
    "        self.train_label = self.train_label.astype(np.float32)\n",
    "        self.test_label = self.test_label.astype(np.float32)\n",
    "\n",
    "        # 统计相关信息\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        # 从train_data中随机抽出batch_size个数据\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        # np数组可以接受list索引，返回list索引对应的值, 原生数据不支持\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义CNN模型\n",
    "和MLP相比，只是新加入了卷积层和池化层，这里的网络结构并不唯一，可以增加、删除、调整CNN的网络结构和参数，以达到更好的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        # 继承父类的属性和方法\n",
    "        super().__init__()\n",
    "        # 定义网络层\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            # 卷积层神经元（卷积核）数目, 默认使用kernel_initializer默认使用glorot_uniform进行初始化，简单来讲就是有32个不一样的卷积核，可以指定kernel_initializer\n",
    "            filters=32,\n",
    "            # 感受野大小\n",
    "            kernel_size=[5, 5],\n",
    "            # padding策略, same/vaild, same表示图片卷积后大小不变，valid表示卷积后图像减小（不对标远进行填充）\n",
    "            padding='same',\n",
    "            # 激活函数\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "\n",
    "        self.pool1 = layers.MaxPool2D(\n",
    "            pool_size=[2,2],\n",
    "            strides=2\n",
    "        )\n",
    "\n",
    "        self.conv2 = layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5,5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "\n",
    "        self.pool2 = layers.MaxPool2D(pool_size=[2,2], strides=2)\n",
    "        # TODO, 和Flatten的区别是什么\n",
    "        self.flatten = layers.Reshape(target_shape=(7*7*64, ))\n",
    "        self.dense1 = layers.Dense(units=1024, activation=tf.nn.relu)\n",
    "        self.dense2 = layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参和实例化对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参\n",
    "batch_size = 50\n",
    "epoch = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化数据和模型对象\n",
    "mnist = MNistLoader()\n",
    "cnn = CNN()\n",
    "\n",
    "# \n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "batch 0 \t loss: 2.305305\nbatch 500 \t loss: 0.015411\nbatch 1000 \t loss: 0.003332\nbatch 1500 \t loss: 0.003056\nbatch 2000 \t loss: 0.044779\nbatch 2500 \t loss: 0.002426\nbatch 3000 \t loss: 0.002162\nbatch 3500 \t loss: 0.035119\nbatch 4000 \t loss: 0.006237\nbatch 4500 \t loss: 0.001408\nbatch 5000 \t loss: 0.029309\nbatch 5500 \t loss: 0.001738\n"
    }
   ],
   "source": [
    "# num_batches \n",
    "num_batches = int(mnist.num_train_data*epoch//batch_size)\n",
    "# 循环喂数据\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = mnist.get_batch(batch_size=batch_size)\n",
    "    # 记录梯度信息\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 默认调用call方法\n",
    "        y_pred = cnn(X)\n",
    "        # 计算Loss\n",
    "        loss = tf.losses.sparse_categorical_crossentropy(y_pred=y_pred, y_true=y)\n",
    "        # 每个类别的误差平均值\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        if batch_index % 500 == 0:\n",
    "            print(\"batch %d \\t loss: %f\" %(batch_index, loss))\n",
    "    # 梯度更新\n",
    "    grads = tape.gradient(loss, cnn.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, cnn.variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证指标\n",
    "这里还是使用sparse_acc来进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "test_acc: 0.991600\n"
    }
   ],
   "source": [
    "# # 定义指标对象\n",
    "# sparse_acc = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "\n",
    "# # 使用测试集进行验证\n",
    "# batch_num = int(mnist.num_test_data / batch_size)\n",
    "# for batch_index in range(batch_num):\n",
    "#     start_index, end_index = batch_index*batch_size, (batch_index+1)*batch_size\n",
    "#     y_pred = cnn.predict(mnist.test_data[start_index:end_index])\n",
    "#     # 更新\n",
    "#     # sparse_acc , y_true是数值， Y_pred为概率，如果y_true对应位置的值为y_pred对应的最大值的索引，则预测正确\n",
    "#     # 如 y_true = [[2, 1]] y_pred=[[0.5, 0.4, 0.1], [0.9, 0.05, 0.05]] 则 acc=1/2\n",
    "#     sparse_acc.update_state(mnist.test_label[start_index:end_index], y_pred)\n",
    "# print(sparse_acc.weights)\n",
    "# print(\"test_acc: %f\" % sparse_acc.result())\n",
    "\n",
    "def acc():\n",
    "    # 定义检测指标对象\n",
    "    sparse_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    batch_num= int(mnist.num_test_data//batch_size)\n",
    "\n",
    "    for batch_index in range(batch_num):\n",
    "        start_index, end_index = batch_index * batch_size, (batch_index+1)*batch_size\n",
    "        y_pred = cnn.predict(mnist.test_data[start_index: end_index])\n",
    "        sparse_acc.update_state(mnist.test_label[start_index:end_index], y_pred)\n",
    "    print(\"test_acc: %f\" % sparse_acc.result())\n",
    "acc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，相对与MLP，准确率有很大的提升.  \n",
    "事实上，通过改变网络结构（比如加入dropout层防止过拟合）准确率还有进一步的提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用keras中预定义的经典卷积神经网络结构\n",
    "\n",
    "tf.keras.applications中有一些预定义号的经典卷积神经网络结构,  \n",
    "如VGG16、 VGG19、ResNet、MobelNet等。  \n",
    "可以直接调用这些经典的卷积网络，甚至可以加载于训练的参数，而无需手动定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n14540800/14536120 [==============================] - 39s 3us/step\n"
    }
   ],
   "source": [
    "# 获取模型参数\n",
    "model = tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当执行上述代码时，tf会自动下载预训练的参数。  \n",
    "也可以通过设置weights参数为None来随机初始化变量。  \n",
    "\n",
    "每个网络都有自己的详细参数设置，一些共同的参数如下：\n",
    "\n",
    "- input_shape: 输入tensor的形状， 大多默认为244*244*3。一般下限为 32\\*32或75\\*75\n",
    "- include_top: 网络的最后是否包含全链接层，默认为true\n",
    "- weights: 预训练权值，默认为\"imageNet\", 即载入当前模型在imageNet数据集上预训练的权值，需要随机初始化可以设为None\n",
    "- classes: 分类数，默认为1000. 修改参数需要include_top参数为true，且weights参数为None\n",
    "\n",
    "各个网络的参数可以参见keras文档: https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些预定义的经典模型，其中某些层在训练和测试时的行为是不同的。  \n",
    "在训练时需要手动设置训练状态，告诉模型『当前是可训练状态』  \n",
    "一般通过\n",
    "```python\n",
    "    tf.keras.backend.set_learning_phase(True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch 0 \t loss: 0.809273\ntf.Tensor(\n[[2.69431263e-01 1.00698983e-02 4.47971039e-02 6.73688710e-01\n  2.01298296e-03]\n [2.95165237e-02 7.47561157e-02 2.15814456e-01 5.03735617e-03\n  6.74875557e-01]\n [2.47800305e-01 2.09581748e-01 1.59890577e-01 3.35740186e-02\n  3.49153370e-01]\n [4.32144970e-01 2.65731782e-01 5.87650463e-02 2.03406423e-01\n  3.99518423e-02]\n [4.69512343e-02 3.16987629e-03 5.92980869e-02 8.89981329e-01\n  5.99448860e-04]\n [4.40175235e-02 1.30770579e-01 5.33765972e-01 2.30252355e-01\n  6.11935779e-02]\n [1.07719209e-02 4.40990448e-01 6.20516352e-02 4.59124655e-01\n  2.70612873e-02]\n [9.88133624e-02 7.66755402e-01 2.95258556e-02 5.15603237e-02\n  5.33450618e-02]\n [3.98960084e-01 3.30446094e-01 6.17346503e-02 1.46469161e-01\n  6.23899847e-02]\n [8.07706892e-01 8.65092650e-02 2.34300084e-02 1.36202360e-02\n  6.87335953e-02]\n [3.31573305e-04 3.43859283e-04 9.84074831e-01 3.31891258e-03\n  1.19307842e-02]\n [8.97342563e-01 5.34380451e-02 1.12532005e-02 9.19776410e-03\n  2.87683681e-02]\n [2.12633628e-02 3.36420513e-03 6.46217391e-02 9.09789741e-01\n  9.60878504e-04]\n [3.30608726e-01 3.49169075e-01 7.66640455e-02 1.33683234e-01\n  1.09874934e-01]\n [6.95894539e-01 1.81787610e-01 2.93592121e-02 4.08087708e-02\n  5.21499254e-02]\n [9.03783441e-01 6.36325106e-02 7.47314189e-03 4.88966377e-03\n  2.02213321e-02]\n [1.18552614e-03 5.55141969e-03 5.58813512e-01 2.00999202e-03\n  4.32439595e-01]\n [1.48103060e-02 8.70138824e-01 2.91733705e-02 2.86565386e-02\n  5.72211146e-02]\n [2.10294072e-02 1.00066595e-01 5.40706158e-01 6.38207123e-02\n  2.74377108e-01]\n [1.08930231e-04 2.98162014e-03 3.01619142e-01 2.30626407e-04\n  6.95059717e-01]], shape=(20, 5), dtype=float32)\nepoch 1 \t loss: 1.168150\ntf.Tensor(\n[[5.22647798e-01 7.09611252e-02 6.30151629e-02 4.75152135e-02\n  2.95860678e-01]\n [5.54467067e-02 3.61388113e-04 3.01364940e-02 9.13737595e-01\n  3.17878730e-04]\n [2.07634792e-01 2.00469717e-01 1.72687411e-01 2.03451086e-02\n  3.98862958e-01]\n [3.72376218e-02 6.54500769e-03 3.58587429e-02 9.19692993e-01\n  6.65637141e-04]\n [4.23888154e-02 5.04438430e-02 1.69783577e-01 1.61948409e-02\n  7.21188903e-01]\n [3.29276435e-02 5.89861989e-01 2.15692118e-01 9.62148011e-02\n  6.53034002e-02]\n [2.54872022e-03 4.25433367e-03 3.64461690e-01 6.91186928e-04\n  6.28044128e-01]\n [8.05465430e-02 1.76774219e-01 2.80755490e-01 1.70850437e-02\n  4.44838703e-01]\n [5.02099283e-02 6.44378439e-02 4.37018871e-01 4.41154003e-01\n  7.17935059e-03]\n [1.95648067e-06 1.04811843e-05 1.61596984e-01 9.64634091e-06\n  8.38380933e-01]\n [4.39829886e-01 2.52120107e-01 8.24543908e-02 2.24521793e-02\n  2.03143388e-01]\n [1.11314684e-01 8.08278739e-01 4.40367050e-02 1.57053657e-02\n  2.06644833e-02]\n [1.07399248e-01 2.86845982e-01 2.24958763e-01 2.01910064e-01\n  1.78885996e-01]\n [9.11991179e-01 5.06893620e-02 9.73552838e-03 5.73282829e-03\n  2.18511317e-02]\n [7.28784874e-02 5.99310756e-01 1.10715233e-01 4.22394946e-02\n  1.74856082e-01]\n [1.67294242e-03 5.19948965e-03 2.00554669e-01 2.09374633e-03\n  7.90479183e-01]\n [3.40512581e-02 2.33166497e-02 1.21929020e-01 1.14887459e-02\n  8.09214354e-01]\n [3.97450298e-01 3.05226564e-01 1.21491410e-01 4.28785495e-02\n  1.32953152e-01]\n [8.36369276e-01 5.10874055e-02 3.20870802e-02 3.80425677e-02\n  4.24136147e-02]\n [1.61631107e-01 9.37598664e-03 4.64475565e-02 7.80540943e-01\n  2.00445717e-03]], shape=(20, 5), dtype=float32)\nepoch 2 \t loss: 0.773273\ntf.Tensor(\n[[8.76390189e-03 8.73699844e-01 2.84141414e-02 2.04425771e-03\n  8.70779827e-02]\n [1.50944616e-04 6.77533739e-04 1.30949661e-01 1.06755726e-03\n  8.67154300e-01]\n [8.63054454e-01 9.57083255e-02 6.46582851e-03 3.38077708e-03\n  3.13905478e-02]\n [6.25806376e-02 2.25483879e-01 7.76948705e-02 3.00154067e-03\n  6.31239057e-01]\n [5.24830422e-04 9.80625629e-01 5.27010718e-03 1.18357784e-04\n  1.34611307e-02]\n [2.00801957e-02 4.86692833e-03 2.12296061e-02 9.51361477e-01\n  2.46180268e-03]\n [8.05106312e-02 4.42534685e-01 6.81704506e-02 4.46330830e-02\n  3.64151120e-01]\n [6.23650610e-01 2.87069768e-01 1.11528113e-02 2.02199933e-03\n  7.61048049e-02]\n [2.47526076e-03 9.42286134e-01 1.11072278e-02 2.00853901e-04\n  4.39305678e-02]\n [1.11999912e-02 1.78910836e-04 8.04388374e-02 9.07392323e-01\n  7.90012942e-04]\n [8.47087521e-03 3.13872993e-02 7.03249156e-01 4.63212933e-03\n  2.52260417e-01]\n [5.97918749e-01 2.74879616e-02 1.99385881e-02 3.47919643e-01\n  6.73507480e-03]\n [5.28843284e-01 2.66260684e-01 5.67870252e-02 2.35618893e-02\n  1.24547169e-01]\n [7.49938097e-03 2.49474688e-04 3.04562785e-02 9.60899472e-01\n  8.95438483e-04]\n [1.43922237e-03 5.14852209e-03 7.49843895e-01 3.95675413e-02\n  2.04000786e-01]\n [2.11929053e-01 3.29977632e-01 1.53913677e-01 2.97352318e-02\n  2.74444401e-01]\n [1.59114564e-03 3.06288060e-03 1.10578671e-01 1.52076490e-03\n  8.83246481e-01]\n [2.23496160e-03 7.93582469e-04 9.68358397e-01 3.91558604e-03\n  2.46974770e-02]\n [6.08276784e-01 7.53445849e-02 5.40544912e-02 2.36952275e-01\n  2.53719389e-02]\n [1.93987377e-02 5.17850975e-04 7.04330727e-02 9.07769322e-01\n  1.88112271e-03]], shape=(20, 5), dtype=float32)\nepoch 3 \t loss: 0.804975\ntf.Tensor(\n[[7.49353588e-01 5.38484864e-02 1.02837626e-02 6.08628942e-03\n  1.80427864e-01]\n [1.56978723e-02 8.26668809e-04 1.03749065e-02 9.72032368e-01\n  1.06830907e-03]\n [5.27610257e-03 4.59199073e-04 5.80786616e-02 9.33315635e-01\n  2.87033920e-03]\n [4.22170497e-02 8.76174510e-01 2.94035804e-02 1.46271661e-03\n  5.07420935e-02]\n [4.94377105e-04 3.04114097e-03 4.93240327e-01 8.59041698e-03\n  4.94633704e-01]\n [3.63709778e-01 1.75726831e-01 9.28171501e-02 3.85907516e-02\n  3.29155564e-01]\n [3.90826026e-03 7.32921762e-03 7.78994977e-01 1.39841558e-02\n  1.95783421e-01]\n [4.90902990e-01 3.87897611e-01 3.37250978e-02 8.60069040e-03\n  7.88736194e-02]\n [6.89144293e-03 9.05145518e-03 5.93574531e-02 9.00637031e-01\n  2.40625869e-02]\n [1.62584316e-02 2.15279055e-04 3.33213760e-03 9.80008841e-01\n  1.85325684e-04]\n [1.99127384e-02 2.03760207e-01 7.17078805e-01 1.50983548e-02\n  4.41498607e-02]\n [3.45669001e-01 1.95483658e-02 3.34524289e-02 5.29728949e-01\n  7.16011450e-02]\n [6.75933063e-01 5.61556332e-02 4.32637185e-02 1.28329054e-01\n  9.63184536e-02]\n [5.26792312e-04 1.10343294e-02 9.66650307e-01 1.21620949e-03\n  2.05722973e-02]\n [3.34404439e-01 3.37703973e-02 3.20711359e-02 2.78388392e-02\n  5.71915269e-01]\n [5.80406701e-03 5.99525273e-02 8.91957998e-01 1.28680049e-02\n  2.94174049e-02]\n [1.16220070e-03 1.75534433e-03 4.41717774e-01 9.08440910e-03\n  5.46280265e-01]\n [6.59904405e-02 6.86202824e-01 4.37237248e-02 1.06234401e-02\n  1.93459615e-01]\n [5.36316097e-01 4.78873588e-03 7.34581053e-03 4.46441770e-01\n  5.10759279e-03]\n [9.37063131e-04 1.79729785e-03 8.60333502e-01 2.72402912e-03\n  1.34208128e-01]], shape=(20, 5), dtype=float32)\nepoch 4 \t loss: 0.734670\ntf.Tensor(\n[[1.30373091e-01 1.29885629e-01 1.98458284e-01 2.56888643e-02\n  5.15594125e-01]\n [4.50757565e-03 2.34808270e-02 6.54880941e-01 7.76345376e-03\n  3.09367239e-01]\n [4.16503812e-04 9.98768270e-01 1.86015241e-04 5.53257763e-04\n  7.60096009e-05]\n [1.16480412e-02 9.77471888e-01 6.44723326e-03 1.09174929e-03\n  3.34105524e-03]\n [8.44824761e-02 1.25142619e-01 2.42292687e-01 2.55691826e-01\n  2.92390406e-01]\n [1.88226514e-02 2.70717666e-02 2.98190892e-01 7.37865036e-03\n  6.48535967e-01]\n [6.89542666e-02 2.17161477e-02 1.12810589e-01 7.64466345e-01\n  3.20526920e-02]\n [1.07731614e-02 3.51851322e-02 2.40638018e-01 2.93760411e-02\n  6.84027731e-01]\n [8.99970293e-01 2.49908958e-02 1.49443829e-02 1.13017438e-03\n  5.89643121e-02]\n [5.55986576e-02 5.14217280e-02 3.14014375e-01 1.73755556e-01\n  4.05209690e-01]\n [3.81425139e-04 4.27822495e-04 9.63371694e-01 3.08589078e-03\n  3.27331014e-02]\n [5.56232572e-01 8.44502747e-02 1.21498212e-01 5.96503466e-02\n  1.78168595e-01]\n [5.80624938e-01 1.56588674e-01 1.84876621e-01 3.27318870e-02\n  4.51778397e-02]\n [3.28075476e-02 1.66235026e-04 7.42814038e-04 9.66136515e-01\n  1.46865947e-04]\n [3.26638925e-03 4.96498704e-01 3.36155146e-01 2.43540071e-02\n  1.39725745e-01]\n [4.05091971e-01 1.47434756e-01 1.01707377e-01 1.82431769e-02\n  3.27522755e-01]\n [1.06162295e-01 2.00431183e-01 1.34377599e-01 1.19598797e-02\n  5.47069073e-01]\n [1.41739275e-03 9.45791726e-06 3.50065151e-04 9.98210073e-01\n  1.30144754e-05]\n [1.41674769e-03 2.31746002e-04 9.63144124e-01 3.14645320e-02\n  3.74275981e-03]\n [3.49159556e-04 3.18703271e-04 6.10334396e-01 5.82222687e-03\n  3.83175552e-01]], shape=(20, 5), dtype=float32)\n"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 定义超参\n",
    "num_epoch = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 加载数据集\n",
    "# split指定返回的数据集的特定部分，如果不指定则返回所有数据集。 TRAIN为训练集， TEST为测试集\n",
    "# as_supervised: 如果为true，根据数据集特性，将数据集中的每行元素整理为有监督的二元组(input, label), 否则数据集中的每行元素为包含所有特征的字典\n",
    "dataset = tfds.load(\"tf_flowers\", split=tfds.Split.TRAIN, as_supervised=True)\n",
    "# 将图片归一化为0-1之间的值，并打乱. 1024为指定buffer_size\n",
    "dataset = dataset.map(lambda img, label:(tf.image.resize(img, (224,224))/255.0, label)).shuffle(1024).batch(batch_size)\n",
    "\n",
    "# 加载模型\n",
    "model = tf.keras.applications.MobileNetV2(weights=None, classes=5)\n",
    "# 设置优化器\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(num_epoch):\n",
    "    for images, labels in dataset:\n",
    "        # 追踪梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            labels_pred = model(images, training=True)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=labels, y_pred=labels_pred)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        # 梯度更新\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
    "    print(\"epoch %d \\t loss: %f\" %(epoch, loss))\n",
    "    print(labels_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}